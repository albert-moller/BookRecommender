{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goodreads Dataset Procurement and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodreadsDataset:\n",
    "    \n",
    "    def __init__(self, save_path: Path, num_pages: int):\n",
    "        self.save_path = save_path\n",
    "        self.num_pages = num_pages\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\"\n",
    "        }\n",
    "        self.home_url = \"https://www.goodreads.com\"\n",
    "        self.base_url = \"https://www.goodreads.com/list/show/1.Best_Books_Ever?page=\"\n",
    "        self.books_data = []\n",
    "\n",
    "    @staticmethod\n",
    "    def retrieve_genres(headers: dict, book_url: str):\n",
    "        # Intialize empty genres list to store fetched genres.\n",
    "        # Make a request to fetch the book page for the provided book url.\n",
    "        response = requests.get(url=book_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Identify genres using the HTML structure belonging to the genre category.\n",
    "        genres = soup.select('a[href*=\"/genres/\"]')\n",
    "        return genres\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_csv(books_data: list, file_name: str):\n",
    "        df = pd.DataFrame(books_data)\n",
    "        df.to_csv(file_name, index=False)\n",
    "        \n",
    "    @staticmethod\n",
    "    def scrape_bookpage(books_data: list, headers: dict, base_url: str, home_url: str, page: int):\n",
    "        # Formulate bookpage url. \n",
    "        url = base_url + str(page)\n",
    "        # Make a request to fetch the page content\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Find all books within the page content. \n",
    "        books = soup.find_all('tr', itemtype=\"http://schema.org/Book\")\n",
    "        for book in books:\n",
    "            try:\n",
    "                title = book.find('a', class_=\"bookTitle\")\n",
    "                author = book.find('a', class_=\"authorName\")\n",
    "                rating = book.find('span', class_=\"minirating\")\n",
    "                book_url = home_url + title['href']\n",
    "                genres = GoodReadsDataset.retrieve_genres(headers, book_url)\n",
    "                # Remove leading and trailing whitespaces.\n",
    "                title = title.text.strip()\n",
    "                author = author.text.strip()\n",
    "                rating = rating.text.strip()[:4]\n",
    "                genres = [genre.text.strip() for genre in genres]\n",
    "                # Construct dictionary to store fetched book data. \n",
    "                book_data = {\n",
    "                    'Title': title,\n",
    "                    'Author': author,\n",
    "                    'Rating': rating,\n",
    "                    'Genres': genres\n",
    "                }\n",
    "                books_data.append(book_data)\n",
    "                # Implement a request delay, to ensure continous access to scraping API.\n",
    "                time.sleep(2)\n",
    "            except (AttributeError, ValueError):\n",
    "                continue\n",
    "        \n",
    "        return books_data\n",
    "    \n",
    "    def main(self):\n",
    "\n",
    "        filename = \"goodreads_dataset.csv\"\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "\n",
    "        filepath = os.path.join(self.save_path, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            for page in range(self.num_pages):\n",
    "                print(f\"Fetching books metadata from page {page}\")\n",
    "                books_data = self.scrape_bookpage(self.books_data, self.headers, self.base_url, self.home_url, page)\n",
    "                self.books_data.extend(books_data)\n",
    "                self.to_csv(self.books_data, filepath)\n",
    "        else:\n",
    "            print(f\"Dataset CSV file already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching books metadata from page 0\n",
      "Fetching books metadata from page 1\n",
      "Fetching books metadata from page 2\n",
      "Fetching books metadata from page 3\n",
      "Fetching books metadata from page 4\n",
      "Fetching books metadata from page 5\n",
      "Fetching books metadata from page 6\n",
      "Fetching books metadata from page 7\n",
      "Fetching books metadata from page 8\n",
      "Fetching books metadata from page 9\n"
     ]
    }
   ],
   "source": [
    "dataset = GoodreadsDataset(\"./data\", 10)\n",
    "dataset.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
